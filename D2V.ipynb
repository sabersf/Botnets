{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Saber Shokat Fadaee'\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.doc2vec import TaggedDocument, LabeledSentence, Doc2Vec\n",
    "import gensim\n",
    "from sklearn import manifold, datasets\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import multiprocessing\n",
    "import csv\n",
    "import matplotlib as ml\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import re\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_checkerboard\n",
    "from sklearn.datasets import samples_generator as sg\n",
    "from sklearn.cluster.bicluster import SpectralBiclustering\n",
    "from sklearn.cluster.bicluster import SpectralCoclustering\n",
    "\n",
    "from sklearn.cluster.bicluster import SpectralCoclustering\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.externals.six import iteritems\n",
    "from sklearn.datasets.twenty_newsgroups import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "from sklearn.utils.extmath import *\n",
    "from sklearn.metrics import consensus_score\n",
    "\n",
    "import operator\n",
    "\n",
    "storage = {}\n",
    "i = 1.0\n",
    "EID_set = set()\n",
    "botnet_set = set()\n",
    "event_set = set()\n",
    "\n",
    "\n",
    "file1 = open('EID.txt')\n",
    "for line in file1:\n",
    "        EID = line.strip()\n",
    "        EID_set.add(EID)\n",
    "file1.close()\n",
    "\n",
    "file1= open(\"botnets.txt\")\n",
    "for line in file1:\n",
    "    botnet = line.strip()\n",
    "    botnet_set.add(botnet)\n",
    "file1.close()\n",
    "\n",
    "EID_set = sorted(EID_set)\n",
    "botnet_set = sorted(botnet_set)\n",
    "event_set = sorted(event_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = np.loadtxt(\"count.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "botnet_family = []\n",
    "file1= open(\"bot_relations.txt\")\n",
    "for line in file1:\n",
    "    botnet_family.append(line.strip().split())\n",
    "file1.close()\n",
    "#Plus one for the unidentified classes\n",
    "num_classes = len(botnet_family) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def in_list(item,L):\n",
    "    for i in L:\n",
    "        if item in i:\n",
    "            return L.index(i)\n",
    "    return num_classes - 1\n",
    "def bot_to_vector(bot):\n",
    "    output = [0] * 23\n",
    "    output[in_list(bot, botnet_family)] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set colors to each category\n",
    "def sec_to_col(argument):\n",
    "    switcher = {\n",
    "\t\t'Aerospace/Defense': 'aqua',\n",
    "\t\t'Business Services': 'blueviolet',\n",
    "\t\t'Consumer Goods': 'brown',\n",
    "\t\t'Education': 'coral',\n",
    "\t\t'Energy/Resources': 'crimson',\n",
    "\t\t'Engineering': 'darkgreen',\n",
    "\t\t'Finance': 'gold',\n",
    "\t\t'Food Production': 'green',\n",
    "\t\t'Government/Politics': 'lime',\n",
    "\t\t'Healthcare/Wellness': 'magenta',\n",
    "\t\t'Insurance': 'mintcream',\n",
    "\t\t'Legal': 'olive',\n",
    "\t\t'Manufacturing': 'orchid',\n",
    "\t\t'Media/Entertainment': 'peru',\n",
    "\t\t'Nonprofit/NGO': 'purple',\n",
    "\t\t'Real Estate': 'red',\n",
    "\t\t'Retail': 'skyblue',\n",
    "\t\t'Technology': 'silver',\n",
    "\t\t'Telecommunications': 'tomato',\n",
    "\t\t'Tourism/Hospitality': 'peachpuff',\n",
    "\t\t'Transportation': 'rosybrown',\n",
    "\t\t'Unknown': 'dimgray',\n",
    "\t\t'Utilities': 'royalblue',\n",
    "    }\n",
    "    return switcher.get(argument, \"yellow\")\n",
    "\n",
    "\n",
    "\n",
    "#Set color to the different sizes\n",
    "\t\n",
    "def size_to_col(argument):\n",
    "    switcher = {\n",
    "\t\t'0-100': 'red',\n",
    "\t\t'100-1000': 'blue',\n",
    "\t\t'1000-10000': 'brown',\n",
    "\t\t'10000-50000': 'green',\n",
    "\t\t'50000+': 'gold',\n",
    "\t\t'Unknown': 'lime',\n",
    "    }\n",
    "    return switcher.get(argument, \"yellow\")\n",
    "\n",
    "# Assigns the topics to the documents in corpus\n",
    "\n",
    "col = []\n",
    "col_size = []\n",
    "\n",
    "sector = {}\n",
    "count_range = {}\n",
    "\n",
    "#Adding extra information\n",
    "with open('extra.csv', 'rb' ) as theFile:\n",
    "    reader = csv.DictReader( theFile )\n",
    "    for line in reader:\n",
    "\t\tind = int(line['']) \n",
    "\t\teid = line['entity_id_hash']\n",
    "\t\tsec = line['industry_sector']\n",
    "\t\tcnt = line['employee_count_range']\n",
    "\t\tsector[eid] = sec\n",
    "\t\tcount_range[eid] = cnt\n",
    "\n",
    "#Set numbers to each category\n",
    "def sec_to_num(argument):\n",
    "    switcher = {\n",
    "\t\t'Aerospace/Defense': 0,\n",
    "\t\t'Business Services': 1,\n",
    "\t\t'Consumer Goods': 2,\n",
    "\t\t'Education': 3,\n",
    "\t\t'Energy/Resources': 4,\n",
    "\t\t'Engineering': 5,\n",
    "\t\t'Finance': 6,\n",
    "\t\t'Food Production': 7,\n",
    "\t\t'Government/Politics': 8,\n",
    "\t\t'Healthcare/Wellness': 9,\n",
    "\t\t'Insurance': 10,\n",
    "\t\t'Legal': 11,\n",
    "\t\t'Manufacturing': 12,\n",
    "\t\t'Media/Entertainment': 13,\n",
    "\t\t'Nonprofit/NGO': 14,\n",
    "\t\t'Real Estate': 15,\n",
    "\t\t'Retail': 16,\n",
    "\t\t'Technology': 17,\n",
    "\t\t'Telecommunications': 18,\n",
    "\t\t'Tourism/Hospitality': 19,\n",
    "\t\t'Transportation': 20,\n",
    "\t\t'Unknown': 21,\n",
    "\t\t'Utilities': 22,\n",
    "    }\n",
    "    return switcher.get(argument, 23)\n",
    "#Set numbers to each size\n",
    "def size_to_num(argument):\n",
    "    switcher = {\n",
    "\t\t'0-100': 0,\n",
    "\t\t'100-1000': 1,\n",
    "\t\t'1000-10000': 2,\n",
    "\t\t'10000-50000': 3,\n",
    "\t\t'50000+': 4,\n",
    "\t\t'Unknown': 5,\n",
    "    }\n",
    "    return switcher.get(argument, 6)\n",
    "\n",
    "#Set category to each number\n",
    "def num_to_sec(argument):\n",
    "    switcher = {\n",
    "\t\t0:'Aerospace/Defense',\n",
    "\t\t1:'Business Services',\n",
    "\t\t2:'Consumer Goods',\n",
    "\t\t3:'Education',\n",
    "\t\t4:'Energy/Resources',\n",
    "\t\t5:'Engineering',\n",
    "\t\t6:'Finance',\n",
    "\t\t7:'Food Production',\n",
    "\t\t8:'Government/Politics',\n",
    "\t\t9:'Healthcare/Wellness',\n",
    "\t\t10:'Insurance',\n",
    "\t\t11:'Legal',\n",
    "\t\t12:'Manufacturing',\n",
    "\t\t13:'Media/Entertainment',\n",
    "\t\t14:'Nonprofit/NGO',\n",
    "\t\t15:'Real Estate',\n",
    "\t\t16:'Retail',\n",
    "\t\t17:'Technology',\n",
    "\t\t18:'Telecommunications',\n",
    "\t\t19:'Tourism/Hospitality',\n",
    "\t\t20:'Transportation',\n",
    "\t\t21:'Unknown',\n",
    "\t\t22:'Utilities',\n",
    "    }\n",
    "    return switcher.get(argument,23)\n",
    "#Set numbers to each size\n",
    "def num_to_size(argument):\n",
    "    switcher = {\n",
    "\t\t0:'0-100',\n",
    "\t\t1:'100-1000',\n",
    "\t\t2:'1000-10000',\n",
    "\t\t3:'10000-50000',\n",
    "\t\t4:'50000+',\n",
    "\t\t5:'Unknown',\n",
    "    }\n",
    "    return switcher.get(argument, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def included_entry(entry_name):\n",
    "    if sector[entry_name] == 'Education':\n",
    "        return False\n",
    "    if sector[entry_name] == 'Technology':\n",
    "        return False\n",
    "    if sector[entry_name] == 'Tourism/Hospitality':\n",
    "        return False\n",
    "    if sector[entry_name] == 'Telecommunications':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3879"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(included_entry(entity) for entity in EID_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_new1 = np.zeros((207,sum(included_entry(entity) for entity in EID_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build a new count matrix excluding the unwanted sectors\n",
    "index = 0\n",
    "EID_set_new = []\n",
    "for i in range(len(EID_set)):\n",
    "    if included_entry(EID_set[i]):\n",
    "        count_new1[:,index] = count[:,i]\n",
    "        EID_set_new.append(EID_set[i])\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_new = np.zeros((num_classes,sum(included_entry(entity) for entity in EID_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(botnet_set)):\n",
    "    count_new[in_list(botnet_set[i], botnet_family) ,:] += count_new1[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 3879)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Group: ', 1, 554588.0)\n",
      "('Group: ', 2, 2.0)\n",
      "('Group: ', 3, 0.0)\n",
      "('Group: ', 4, 3628.0)\n",
      "('Group: ', 5, 2086.0)\n",
      "('Group: ', 6, 2539.0)\n",
      "('Group: ', 7, 156272.0)\n",
      "('Group: ', 8, 7167.0)\n",
      "('Group: ', 9, 3.0)\n",
      "('Group: ', 10, 150.0)\n",
      "('Group: ', 11, 34789.0)\n",
      "('Group: ', 12, 1297.0)\n",
      "('Group: ', 13, 3.0)\n",
      "('Group: ', 14, 3920.0)\n",
      "('Group: ', 15, 844704.0)\n",
      "('Group: ', 16, 6659.0)\n",
      "('Group: ', 17, 12042.0)\n",
      "('Group: ', 18, 3408069.0)\n",
      "('Group: ', 19, 0.0)\n",
      "('Group: ', 20, 184976.0)\n",
      "('Group: ', 21, 76927.0)\n",
      "('Group: ', 22, 4.0)\n",
      "('Group: ', 23, 398817.0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_classes):\n",
    "    print(\"Group: \", i+1, sum(count_new[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5698642.0\n"
     ]
    }
   ],
   "source": [
    "sum_count_new = 0\n",
    "for i in range(num_classes):\n",
    "    sum_count_new += sum(count_new[i,:])\n",
    "print(sum_count_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sectors_count(botnet_group):\n",
    "    sectors_count = [0]*23\n",
    "    res = dict()\n",
    "    for i in range(len(EID_set_new)):\n",
    "        if count_new[botnet_group,i] > 0:\n",
    "            sectors_count[sec_to_num(sector[EID_set_new[i]])] += count_new[botnet_group,i]\n",
    "    for i in range(23):\n",
    "        res[num_to_sec(i)] = sectors_count[i]\n",
    "    return res\n",
    "\n",
    "def sectors_count_botnet(bot):\n",
    "    sectors_count = [0]*23\n",
    "    for i in range(len(EID_set_new)):\n",
    "        if count_new1[bot,i] > 0:\n",
    "            sectors_count[sec_to_num(sector[EID_set_new[i]])] += count_new1[bot,i]\n",
    "    return sectors_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_classes-2):\n",
    "    x = range(23)\n",
    "    y = sectors_count(i).values()\n",
    "    labels = sectors_count(i).keys()\n",
    "    plt.figure(figsize=(16,18))\n",
    "    plt.plot(x, y, 'r-')\n",
    "    plt.title((\"Group: %d. Contains botnets like: %s %s\")%(i+1,botnet_family[i][0],botnet_family[i][1]))\n",
    "    plt.xticks(x, labels, rotation='vertical')\n",
    "    plt.savefig(\"Group_%d.png\"%(i+1))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input1 = []\n",
    "for i in range(len(botnet_set)):\n",
    "    input1.append(sectors_count_botnet(i))\n",
    "output = []\n",
    "for bot in botnet_set:\n",
    "    output.append(bot_to_vector(bot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Initial input shape: (None, 23)\n",
      "--------------------------------------------------------------------------------\n",
      "Layer (name)                  Output Shape                  Param #             \n",
      "--------------------------------------------------------------------------------\n",
      "Dense (Unnamed)               (None, 16)                    384                 \n",
      "Activation (Unnamed)          (None, 16)                    0                   \n",
      "Dropout (Unnamed)             (None, 16)                    0                   \n",
      "Dense (Unnamed)               (None, 8)                     136                 \n",
      "Activation (Unnamed)          (None, 8)                     0                   \n",
      "Dropout (Unnamed)             (None, 8)                     0                   \n",
      "Dense (Unnamed)               (None, 4)                     36                  \n",
      "Activation (Unnamed)          (None, 4)                     0                   \n",
      "Dropout (Unnamed)             (None, 4)                     0                   \n",
      "Dense (Unnamed)               (None, 16)                    80                  \n",
      "Activation (Unnamed)          (None, 16)                    0                   \n",
      "Dropout (Unnamed)             (None, 16)                    0                   \n",
      "Dense (Unnamed)               (None, 23)                    391                 \n",
      "Activation (Unnamed)          (None, 23)                    0                   \n",
      "--------------------------------------------------------------------------------\n",
      "Total params: 1027\n",
      "--------------------------------------------------------------------------------\n",
      "Train on 164 samples, validate on 42 samples\n",
      "Epoch 1/25\n",
      "164/164 [==============================] - 0s - loss: 3.1179 - val_loss: 3.0333\n",
      "Epoch 2/25\n",
      "164/164 [==============================] - 0s - loss: 2.9240 - val_loss: 2.8591\n",
      "Epoch 3/25\n",
      "164/164 [==============================] - 0s - loss: 2.7318 - val_loss: 2.6831\n",
      "Epoch 4/25\n",
      "164/164 [==============================] - 0s - loss: 2.5457 - val_loss: 2.5146\n",
      "Epoch 5/25\n",
      "164/164 [==============================] - 0s - loss: 2.4159 - val_loss: 2.3728\n",
      "Epoch 6/25\n",
      "164/164 [==============================] - 0s - loss: 2.2729 - val_loss: 2.2728\n",
      "Epoch 7/25\n",
      "164/164 [==============================] - 0s - loss: 2.1804 - val_loss: 2.2069\n",
      "Epoch 8/25\n",
      "164/164 [==============================] - 0s - loss: 2.1355 - val_loss: 2.1707\n",
      "Epoch 9/25\n",
      "164/164 [==============================] - 0s - loss: 2.1285 - val_loss: 2.1506\n",
      "Epoch 10/25\n",
      "164/164 [==============================] - 0s - loss: 2.0955 - val_loss: 2.1453\n",
      "Epoch 11/25\n",
      "164/164 [==============================] - 0s - loss: 2.0496 - val_loss: 2.1401\n",
      "Epoch 12/25\n",
      "164/164 [==============================] - 0s - loss: 2.0636 - val_loss: 2.1347\n",
      "Epoch 13/25\n",
      "164/164 [==============================] - 0s - loss: 2.0687 - val_loss: 2.1344\n",
      "Epoch 14/25\n",
      "164/164 [==============================] - 0s - loss: 2.0349 - val_loss: 2.1330\n",
      "Epoch 15/25\n",
      "164/164 [==============================] - 0s - loss: 2.0750 - val_loss: 2.1330\n",
      "Epoch 16/25\n",
      "164/164 [==============================] - 0s - loss: 2.0249 - val_loss: 2.1336\n",
      "Epoch 17/25\n",
      "164/164 [==============================] - 0s - loss: 2.0336 - val_loss: 2.1275\n",
      "Epoch 18/25\n",
      "164/164 [==============================] - 0s - loss: 2.0522 - val_loss: 2.1311\n",
      "Epoch 19/25\n",
      "164/164 [==============================] - 0s - loss: 2.0309 - val_loss: 2.1353\n",
      "Epoch 20/25\n",
      "164/164 [==============================] - 0s - loss: 2.0098 - val_loss: 2.1326\n",
      "Epoch 21/25\n",
      "164/164 [==============================] - 0s - loss: 2.0298 - val_loss: 2.1309\n",
      "Epoch 22/25\n",
      "164/164 [==============================] - 0s - loss: 2.0283 - val_loss: 2.1316\n",
      "Epoch 23/25\n",
      "164/164 [==============================] - 0s - loss: 1.9913 - val_loss: 2.1354\n",
      "Epoch 24/25\n",
      "164/164 [==============================] - 0s - loss: 2.0548 - val_loss: 2.1325\n",
      "Epoch 25/25\n",
      "164/164 [==============================] - 0s - loss: 2.0574 - val_loss: 2.1310\n",
      "NB_EPOCH :  25  Score:  2.13097429276  test accuracy:  38.0952380952  Train accuracy:  36.5853658537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "inp = np.array(input1)\n",
    "out = np.array(output)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(inp, out, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(num_classes,)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "\n",
    "model.add(Dense(23))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 4\n",
    "nb_classes = 23\n",
    "nb_epoch = 25\n",
    "#target = open(\"NN_out.txt\", 'w')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(), class_mode=\"categorical\")\n",
    "\n",
    "history = model.fit(X_train, Y_train,  batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "#print('Test score:', score)\n",
    "\n",
    "p = model.predict(X_test)\n",
    "yy = np.argmax(p, axis=1)\n",
    "yyy = np.argmax(Y_test, axis=1)\n",
    "\n",
    "a = np.equal(yy, yyy)\n",
    "test_acc = ( 100.0 * (0.0 + sum(a)) / (len(a) + 0.0 ))\n",
    "\n",
    "p = model.predict(X_train)\n",
    "yy = np.argmax(p, axis=1)\n",
    "yyy = np.argmax(Y_train, axis=1)\n",
    "\n",
    "a = np.equal(yy, yyy)\n",
    "train_acc = ( 100.0 * (0.0 + sum(a)) / (len(a) + 0.0 ))\n",
    "print(\"NB_EPOCH : \" , str(nb_epoch) , \" Score: \" , str(score) , \" test accuracy: \" , str(test_acc) , \" Train accuracy: \"  , str(train_acc) + \"\\n\")\n",
    "#target.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17]\n",
      "[22 17 10 22 22 22 22 17 17 19  5 12 17 17 16  4 22 17 17 17 22 17 21 22  6\n",
      " 22 17  7 12 20 22 17 17 17 15 22 17 13 22 17 17  0]\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(X_test)\n",
    "yy = np.argmax(p, axis=1)\n",
    "yyy = np.argmax(Y_test, axis=1)\n",
    "\n",
    "print(yy)\n",
    "print(yyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "output = []\n",
    "for bot in botnet_set:\n",
    "    output.append(bot_to_vector(bot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_list('Pushdo', botnet_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "botnet_family[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "botnet_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
